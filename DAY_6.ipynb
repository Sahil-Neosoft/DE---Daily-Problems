{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZNnH-LElC4k",
        "outputId": "89008e04-7a97-45b2-cdd3-50dc9d122cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "spark=SparkSession.builder \\\n",
        "      .appName(\"Day 6\") \\\n",
        "      .getOrCreate()"
      ],
      "metadata": {
        "id": "bwCmqKgtlHyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1: PySpark – Rank Employees by Salary within Departments"
      ],
      "metadata": {
        "id": "ps0_SyhZlaYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have a PySpark DataFrame containing employee salaries across departments. Write a PySpark program to rank employees within each department based on salary in descending order."
      ],
      "metadata": {
        "id": "BAeGPSSXlfEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1, \"HR\", 60000),\n",
        "    (2, \"HR\", 75000),\n",
        "    (3, \"HR\", 50000),\n",
        "    (4, \"IT\", 90000),\n",
        "    (5, \"IT\", 85000)\n",
        "]\n",
        "columns = [\"emp_id\", \"dept\", \"salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "zyLbK6j4lMth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window=Window.partitionBy(\"dept\").orderBy(col(\"salary\").desc())\n",
        "result=df.withColumn(\"rank\",dense_rank().over(window)).select(\"emp_id\",\"dept\",\"salary\",\"rank\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCzOSTWAltMq",
        "outputId": "20a3f719-6920-4c23-de3d-6c3fc936d827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------+----+\n",
            "|emp_id|dept|salary|rank|\n",
            "+------+----+------+----+\n",
            "|     2|  HR| 75000|   1|\n",
            "|     1|  HR| 60000|   2|\n",
            "|     3|  HR| 50000|   3|\n",
            "|     4|  IT| 90000|   1|\n",
            "|     5|  IT| 85000|   2|\n",
            "+------+----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2: SQL – Find Products Purchased in All Months of 2025"
      ],
      "metadata": {
        "id": "aULUWhGEtZdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have a table product_sales(product_id, sale_date) where sale_date is a DATE. Write a SQL query to find products that had at least one sale in every calendar month of 2025 (i.e., all 12 months from January to December 2025)."
      ],
      "metadata": {
        "id": "J-iN8gQFtdHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"P1\", \"2025-01-10\"), (\"P1\", \"2025-02-12\"), (\"P1\", \"2025-03-09\"),\n",
        "    (\"P1\", \"2025-04-18\"), (\"P1\", \"2025-05-03\"), (\"P1\", \"2025-06-27\"),\n",
        "    (\"P1\", \"2025-07-14\"), (\"P1\", \"2025-08-21\"), (\"P1\", \"2025-09-02\"),\n",
        "    (\"P1\", \"2025-10-11\"), (\"P1\", \"2025-11-06\"), (\"P1\", \"2025-12-05\"),\n",
        "\n",
        "    (\"P2\", \"2025-01-05\"), (\"P2\", \"2025-02-10\"), (\"P2\", \"2025-03-15\"),\n",
        "    (\"P2\", \"2025-05-20\"), (\"P2\", \"2025-06-08\"), (\"P2\", \"2025-07-22\"),\n",
        "    (\"P2\", \"2025-08-30\"), (\"P2\", \"2025-10-01\"), (\"P2\", \"2025-11-19\"),\n",
        "    (\"P2\", \"2025-12-07\"),\n",
        "\n",
        "    (\"P3\", \"2025-01-02\"), (\"P3\", \"2025-02-14\"), (\"P3\", \"2025-03-03\"),\n",
        "    (\"P3\", \"2025-04-25\"), (\"P3\", \"2025-05-09\"), (\"P3\", \"2025-06-16\"),\n",
        "    (\"P3\", \"2025-07-07\"), (\"P3\", \"2025-08-12\"), (\"P3\", \"2025-09-28\"),\n",
        "    (\"P3\", \"2025-10-20\"), (\"P3\", \"2025-11-03\"), (\"P3\", \"2025-12-29\"),\n",
        "]\n",
        "\n",
        "columns = [\"product_id\", \"sale_date\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns).withColumn(\"sale_date\", to_date(\"sale_date\"))\n",
        "\n",
        "df.createOrReplaceTempView(\"product_sales\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAssWC0-rAMr",
        "outputId": "5c059955-bf25-45df-a59c-1974ab11c045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|product_id| sale_date|\n",
            "+----------+----------+\n",
            "|        P1|2025-01-10|\n",
            "|        P1|2025-02-12|\n",
            "|        P1|2025-03-09|\n",
            "|        P1|2025-04-18|\n",
            "|        P1|2025-05-03|\n",
            "|        P1|2025-06-27|\n",
            "|        P1|2025-07-14|\n",
            "|        P1|2025-08-21|\n",
            "|        P1|2025-09-02|\n",
            "|        P1|2025-10-11|\n",
            "|        P1|2025-11-06|\n",
            "|        P1|2025-12-05|\n",
            "|        P2|2025-01-05|\n",
            "|        P2|2025-02-10|\n",
            "|        P2|2025-03-15|\n",
            "|        P2|2025-05-20|\n",
            "|        P2|2025-06-08|\n",
            "|        P2|2025-07-22|\n",
            "|        P2|2025-08-30|\n",
            "|        P2|2025-10-01|\n",
            "+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=spark.sql(\"\"\"\n",
        "        select product_id from product_sales\n",
        "        where year(sale_date)=2025\n",
        "        group by product_id\n",
        "        having count(*)=12\n",
        "        \"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mICT4N_8kMYq",
        "outputId": "38e440d0-4119-47bc-d7d4-ab613bf8e5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|product_id|\n",
            "+----------+\n",
            "|        P1|\n",
            "|        P3|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}