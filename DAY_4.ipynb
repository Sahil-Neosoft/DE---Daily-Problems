{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WBV5COUBKgz",
        "outputId": "2092dd34-2ea9-445f-bf02-a95373e09d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "spark=SparkSession.builder \\\n",
        "      .appName(\"Day 4\") \\\n",
        "      .getOrCreate()"
      ],
      "metadata": {
        "id": "PXfa7J4tBbOE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1: PySpark – Detect Outlier Transactions per Day\n"
      ],
      "metadata": {
        "id": "NHBIEmNhBy8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement\n",
        "You have a PySpark DataFrame with daily transaction amounts. For each day, identify transactions greater than the average amount for that day (outliers)."
      ],
      "metadata": {
        "id": "1q0R17TXBzyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"2025-01-01\", \"T1\", 100),\n",
        "    (\"2025-01-01\", \"T2\", 200),\n",
        "    (\"2025-01-01\", \"T3\", 500),\n",
        "    (\"2025-01-02\", \"T4\", 300),\n",
        "    (\"2025-01-02\", \"T5\", 400),\n",
        "    (\"2025-01-02\", \"T6\", 600)\n",
        "]\n",
        "columns = [\"txn_date\", \"txn_id\", \"amount\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "KM2DlA2wBfOC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daily_avg = df.groupBy(\"txn_date\").agg(avg(\"amount\").alias(\"avg_amount\"))\n",
        "df_with_avg = df.join(daily_avg, on=\"txn_date\", how=\"inner\")\n",
        "outliers = df_with_avg.filter(col(\"amount\") > col(\"avg_amount\")) \\\n",
        "                      .select(\"txn_date\", \"txn_id\", \"amount\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SuRET92CGnH",
        "outputId": "5970ec37-fd98-455e-b80b-6b21b20e3387"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+------+\n",
            "|  txn_date|txn_id|amount|\n",
            "+----------+------+------+\n",
            "|2025-01-01|    T3|   500|\n",
            "|2025-01-02|    T6|   600|\n",
            "+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2: SQL – Find Employees Always Reporting to the Same Manager"
      ],
      "metadata": {
        "id": "z3mueA-8C7hb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement\n",
        "You have a table employee_manager(emp_id, manager_id, change_date) showing employees' managers over time. Write a SQL query to find employees who never changed their manager across all records.\n",
        "\n"
      ],
      "metadata": {
        "id": "K58Z4BYBDBtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1, 10, \"2025-01-01\"),\n",
        "    (1, 10, \"2025-02-01\"),\n",
        "    (2, 11, \"2025-01-01\"),\n",
        "    (2, 12, \"2025-03-01\"),\n",
        "    (3, 13, \"2025-01-05\")\n",
        "]\n",
        "\n",
        "columns = [\"emp_id\", \"manager_id\", \"change_date\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "df = df.withColumn(\"change_date\", to_date(col(\"change_date\"), \"yyyy-MM-dd\"))\n",
        "\n",
        "df.createOrReplaceTempView(\"employee_manager\")"
      ],
      "metadata": {
        "id": "pXRwulIQCz0w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = spark.sql(\"\"\"\n",
        "    SELECT emp_id\n",
        "    FROM employee_manager\n",
        "    GROUP BY emp_id\n",
        "    HAVING COUNT(DISTINCT manager_id) = 1\n",
        "\"\"\")\n",
        "\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWz2tskqCmmz",
        "outputId": "5e0de44e-a8b2-4e2d-9134-58158fea333c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|emp_id|\n",
            "+------+\n",
            "|     1|\n",
            "|     3|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}